{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f7950f",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf8ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178c006",
   "metadata": {},
   "source": [
    "## **Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87875a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 7)) (1.58.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 9)) (4.13.5)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 10)) (25.1.0)\n",
      "Collecting tiktoken (from -r ../requirements.txt (line 15))\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 20)) (0.3.75)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from -r ../requirements.txt (line 21)) (0.3.11)\n",
      "Requirement already satisfied: pyee<14,>=13 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from playwright->-r ../requirements.txt (line 7)) (13.0.1)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from playwright->-r ../requirements.txt (line 7)) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from pyee<14,>=13->playwright->-r ../requirements.txt (line 7)) (4.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from beautifulsoup4->-r ../requirements.txt (line 9)) (2.8)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from tiktoken->-r ../requirements.txt (line 15)) (2025.9.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from tiktoken->-r ../requirements.txt (line 15)) (2.32.5)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langchain_core->-r ../requirements.txt (line 20)) (0.4.23)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langchain_core->-r ../requirements.txt (line 20)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langchain_core->-r ../requirements.txt (line 20)) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langchain_core->-r ../requirements.txt (line 20)) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langchain_core->-r ../requirements.txt (line 20)) (2.11.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r ../requirements.txt (line 20)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from pydantic>=2.7.4->langchain_core->-r ../requirements.txt (line 20)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from pydantic>=2.7.4->langchain_core->-r ../requirements.txt (line 20)) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from pydantic>=2.7.4->langchain_core->-r ../requirements.txt (line 20)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from requests>=2.26.0->tiktoken->-r ../requirements.txt (line 15)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from requests>=2.26.0->tiktoken->-r ../requirements.txt (line 15)) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\envs\\pyfix\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ../requirements.txt (line 20)) (1.3.1)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/879.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/879.4 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 786.4/879.4 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df9755",
   "metadata": {},
   "source": [
    "## **Setup Working Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5752abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Enviroment Loadeding............\n",
      "============================================================\n",
      "Provider:openrouter\n",
      "Project Root Directory:c:\\UOC pdf\\AI Engineering Bootcamp\\mini-project-03\n",
      "âœ…Environment Loaded\n"
     ]
    }
   ],
   "source": [
    "## Add project root to system path\n",
    "CURRENT_DIR=Path.cwd()\n",
    "PROJECT_ROOT=CURRENT_DIR\n",
    "\n",
    "while not (PROJECT_ROOT/'src').exists() and PROJECT_ROOT!=PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT=PROJECT_ROOT.parent \n",
    "\n",
    "if not (PROJECT_ROOT/'src').exists():\n",
    "    raise Exception(\"Could not find the 'src' folder.Check the folder structure\")\n",
    "\n",
    "## add project root to the python path\n",
    "sys.path.insert(0,str(PROJECT_ROOT))\n",
    "\n",
    "load_dotenv(PROJECT_ROOT/'.env')\n",
    "\n",
    "## check API keys configurations\n",
    "openrouter_api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## check whether API keys there or not\n",
    "if not  openrouter_api_key or not openai_api_key:\n",
    "    raise ValueError(\n",
    "        \"API keys are not Found.\\n\"\n",
    "        \"Please add those API keys into the .env file if there is anything missing.\"\n",
    "    )\n",
    "\n",
    "\n",
    "from src.context_engineering.config import(\n",
    "    VECTOR_DIR,EMBEDDING_MODEL,CRAWL_OUT_DIR,PROVIDER\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Enviroment Loadeding............\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Provider:{PROVIDER}\")\n",
    "print(f\"Project Root Directory:{PROJECT_ROOT}\")\n",
    "print(\"âœ…Environment Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d3fc8",
   "metadata": {},
   "source": [
    "## **Chunking Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04df3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking strategies loaded from the chunking layer\n",
      "Location:src.context_engineering.chunking\n",
      "============================================================\n",
      "Available Chunking Strategies:\n",
      "   1. semantic_chunk      - Split by heading structure\n",
      "   2. fixed_chunk         - Uniform token chunks with overlap\n",
      "   3. sliding_chunk       - Overlapping windows for better recall\n",
      "   4. parent_child_chunk  - Two-tier parent-child chunking\n",
      "   5. late_chunk          - Large base chunks (late splitting)\n",
      "   ðŸ”„ late_retrieval      - Split + context window (retrieval phase)\n"
     ]
    }
   ],
   "source": [
    "from src.context_engineering.chunking.chunkers import Chunking\n",
    "\n",
    "print(\"Chunking strategies loaded from the chunking layer\")\n",
    "print(\"Location:src.context_engineering.chunking\")\n",
    "print(\"=\"*60)\n",
    "print(\"Available Chunking Strategies:\")\n",
    "\n",
    "print(\"   1. semantic_chunk      - Split by heading structure\")\n",
    "print(\"   2. fixed_chunk         - Uniform token chunks with overlap\")\n",
    "print(\"   3. sliding_chunk       - Overlapping windows for better recall\")\n",
    "print(\"   4. parent_child_chunk  - Two-tier parent-child chunking\")\n",
    "print(\"   5. late_chunk          - Large base chunks (late splitting)\")\n",
    "print(\"   ðŸ”„ late_retrieval      - Split + context window (retrieval phase)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add8a6f",
   "metadata": {},
   "source": [
    "## **Load Prime Lands Corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7b49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Documents..............\n",
      "============================================================\n",
      "Numbebr of Documents:20\n",
      "Total content size: 50,479 chars\n",
      "Document Loaded\n"
     ]
    }
   ],
   "source": [
    "## open and read jsonl file \n",
    "corpus_path=PROJECT_ROOT/CRAWL_OUT_DIR/\"prime_lands_corpus.jsonl\"\n",
    "\n",
    "if not corpus_path.exists():\n",
    "    raise FileNotFoundError(\"Corpus can't be found in provided directory.\")\n",
    "\n",
    "with open(corpus_path,\"r\",encoding=\"UTF-8\") as f:\n",
    "    documents=[json.loads(line) for line in f]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Loading Documents..............\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Numbebr of Documents:{len(documents)}\")\n",
    "print(f\"Total content size: {sum(len(d['content']) for d in documents):,} chars\")\n",
    "print(\"Document Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa062290",
   "metadata": {},
   "source": [
    "## **Apply Each Chunking Strategies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232093a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
