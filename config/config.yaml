### Confiuration file for context engineering.
### Contain all the necessary innformation for the project and we can change all the 
### paramters using this document without changign anything in the code structures.

##=====================================
## Peovider Settings
##=====================================
provider:
  ## we set the openrouter as default provider in this project 
  ## we can use openai or gemini as well.
  ## we can access all the llm models using the openrouter as provider
  default: openrouter

  ## Model tier general,strong or reasoning
  tier: general
  ## Open router base url
  openrouter_url: https://openrouter.ai/api/v1

##=====================================
## LLM Configuration
##=====================================
llm:
  temperature: 0.0 ## deteministic
  max_tokens: 2000
  streaming: false

##====================================
## Embeddig Model Configuration
##====================================
embedding:
  ## Model tier default or small
  tier: default
  batch_size: 20
  show_progress: false

# ====================================
# Crawling Configuration
# ====================================
crawling:
  base_url: https://www.primelands.lk
  max_depth: 3
  max_pages: 500
  timeout: 30000
  rate_limit_seconds: 2.0

##====================================
## Project Paths Configuration
##====================================
data_dir: data
chunks_dir: data/chunkings
markdown_dir: data/markdown
processed_dir: data/processed
cache_dir: data/cache

##====================================
## Chunking Configuration
##====================================
chunking:
  ## configure fixed chunking startegy
  fixed_chunk:
    chunk_size: 800
    chunk_overlap: 100
  
  ## configure semantic chunking strategy
  semantic_chunk:
    chunk_size: 1000
    min_chunk_size: 200
  
  ## configure sliding chunknig strategy
  sliding_chunk:
    chunk_size: 512
    overlap: 256
  
  ## configure parent-child chunking starategy
  parent_child_chunk:
    parent_chunk: 1200
    child_chunk: 250
    child_overlap: 50
  
  ## configure late chunking starategy
  late_chunk:
    base_size: 1000
    split_size: 300
    context_window: 150


##===================================
## Retrieval Configuration
##===================================
retrieval:
  top_k: 5
  similarity_threshold: 0.7

# ============================================================================
# CAG(Cache Augmentation Generation) Configuration
# ============================================================================
cag:
  cache_ttl: 86400  # 24 hours in seconds (legacy, use history_ttl_hours)
  max_cache_size: 1000
  similarity_threshold: 0.90  # 0.90-0.95 recommended for paraphrase matching
  history_ttl_hours: 24  # Dynamic history expires after 24 hours

# ============================================================================
# CRAG (Corrective Retrieval Augmentation Generation) Configuration
# ============================================================================
crag:
  confidence_threshold: 0.6
  expanded_k: 8

